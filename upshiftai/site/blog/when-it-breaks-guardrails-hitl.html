<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>When it breaks, who fixes it, and why human-in-the-loop still matters — UpshiftAI Blog</title>
  <meta name="description" content="Three questions experienced engineers ask about AI-powered dependency upgrades—when it breaks, CI/CD guardrails, and why human-in-the-loop still matters.">
  <link rel="icon" href="../favicon.ico" type="image/x-icon">
  <link rel="icon" href="../favicon.svg" type="image/svg+xml">
  <link rel="stylesheet" href="../style.css">
  <style>
    .blog-content { max-width: 680px; margin: 0 auto; padding: 3rem 24px; }
    .blog-meta { color: var(--text-muted); font-size: 0.9rem; margin-bottom: 2rem; }
    .blog-content h1 { font-size: 2.25rem; line-height: 1.2; margin-bottom: 1rem; }
    .blog-content h2 { font-size: 1.5rem; margin-top: 2.5rem; margin-bottom: 1rem; }
    .blog-content p { margin-bottom: 1.5rem; color: var(--text-muted); }
    .blog-content p:first-of-type { font-size: 1.15rem; color: var(--text-main); }
    .blog-content .subtitle { font-size: 1.1rem; color: var(--text-muted); font-style: italic; margin-bottom: 2rem; }
    .blog-content code { background: var(--bg-surface); padding: 0.15rem 0.4rem; border-radius: 4px; font-size: 0.9em; }
    .blog-content ul, .blog-content ol { margin-bottom: 1.5rem; padding-left: 1.5rem; color: var(--text-muted); }
    .blog-content li { margin-bottom: 0.5rem; }
    .blog-content strong { color: var(--text-main); }
    .blog-content hr { border: none; border-top: 1px solid var(--border); margin: 2.5rem 0; }
    .blog-cta { background: var(--bg-surface); border: 1px solid var(--border); border-radius: var(--radius-md); padding: 2rem; text-align: center; margin: 3rem 0; }
    .blog-cta h3 { margin: 0 0 0.5rem; }
    .blog-cta p { margin: 0 0 1rem; font-size: 1rem; }
  </style>
</head>
<body>
  <header class="header">
    <div class="container">
      <a href=".." class="logo">UpshiftAI</a>
      <nav class="desktop-nav">
        <a href="..">Home</a>
        <a href="../docs.html">How it works</a>
        <a href="../dev.html">Developers</a>
        <a href="../pricing.html">Pricing</a>
        <a href="index.html">Blog</a>
        <a href="https://github.com/repairman29/upshift/tree/main/upshiftai" class="nav-cta" target="_blank" rel="noopener">GitHub</a>
      </nav>
    </div>
  </header>

  <article class="blog-content">
    <p class="blog-meta">February 1, 2026 · 5 min read</p>
    <h1>When it breaks, who fixes it, and why human-in-the-loop still matters</h1>
    <p class="subtitle">Three questions experienced engineers ask about AI-powered dependency upgrades—and how we answer them.</p>

    <p>Dependency upgrades are boring until they break something. Then everyone wants to know: <em>when</em> did it break, <em>who</em> is supposed to catch it, and whether we're really letting an AI change code without a human in the loop.</p>
    <p>We get that. Here's how we think about it.</p>

    <h2>"When does it break?"</h2>
    <p><strong>At upgrade time.</strong> Not "sometime after a code push" or "when the moon is full." When you—or your CI—run an upgrade, we change the manifest and lockfile, run your tests, and roll back if tests fail. The break is surfaced <em>at that moment</em> and reverted.</p>
    <p>So:</p>
    <ul>
      <li><strong>You run an upgrade</strong> → We update the manifest and lockfile, then run your test script. If tests fail, we roll back. The "break" is immediate and undone.</li>
      <li><strong>CI runs UpshiftAI</strong> → Same contract. Upgrade → run tests → fail the job (and optionally roll back) if tests fail. CI doesn't self-heal; it <em>surfaces</em> the problem. We use that same guardrail.</li>
      <li><strong>You run a fix</strong> → That's for <em>code</em> changes (LLM-generated fixes for breaking API changes). You run it when you know an upgrade will break code, or after it already did. It's an explicit step, not something that fires automatically on push.</li>
    </ul>
    <p><strong>TL;DR:</strong> "Breaks when?" → When an upgrade is applied and tests run. Tests are the gate.</p>

    <h2>CI/CD and smoke tests: we're not replacing them</h2>
    <p>Today, CI/CD with smoke or integration tests <em>surfaces</em> problems. It doesn't self-heal. We're aligned with that:</p>
    <ul>
      <li>We <strong>run your tests</strong> after every upgrade (if you have a test script). If they fail, we roll back and exit with failure.</li>
      <li>We don't replace CI; we <strong>use the same guardrail</strong>: "tests pass = safe to keep the change."</li>
    </ul>
    <p>Existing CI and test suites stay the source of truth. UpshiftAI adds upgrade + optional code fixes on top of that contract.</p>

    <h2>Self-healing LLM code: why human-in-the-loop still matters</h2>
    <p><strong>LLM-generated code changes should be reviewed.</strong> "Self-healing" by applying AI-generated patches with no oversight is risky. We're not pretending otherwise.</p>
    <p>What we do today:</p>
    <ul>
      <li><strong>Dry-run and confirm</strong> — Preview every suggested change. Review the diff, then apply when you're satisfied.</li>
      <li><strong>Approval for upgrades</strong> — Major (and optionally other) upgrades can require a prompt or webhook approval before we touch the manifest or lockfile. See <a href="how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a> and the <a href="https://github.com/repairman29/upshift/blob/main/upshiftai/docs/HITL.md">HITL doc</a>.</li>
      <li><strong>No silent auto-apply of code fixes</strong> — Fixes are either shown for review (dry-run) or applied only after an explicit confirm (or <code>-y</code> in automation, where <em>you've</em> chosen to trust the pipeline).</li>
    </ul>
    <p>Recommendation: treat <strong>dependency upgrades</strong> as guardrailed by tests and optional approval. Treat <strong>LLM-generated code fixes</strong> as human-in-the-loop: review (dry-run, PR, or approval workflow) before merging. For how we implement approval (prompt vs webhook vs none) and quick setup, see <a href="how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a>; for webhook payloads and event hooks, see <a href="https://github.com/repairman29/upshift/blob/main/upshiftai/docs/HITL.md">HITL in the docs</a>.</p>

    <hr>

    <p>So: it breaks at upgrade time, tests are the guardrail, and we don't self-heal code without giving you a way to stay in the loop.</p>

    <p style="margin-top:2rem;"><strong>Related:</strong> <a href="how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a> — prompt vs webhook vs none, config, and quick setup for oversight.</p>

    <div class="blog-cta">
      <h3>Try UpshiftAI</h3>
      <p>Analyze dependencies, get AI insights, and upgrade with guardrails.</p>
      <a href=".." class="btn btn-primary">Get Started</a>
    </div>
  </article>

  <footer class="footer">
    <div class="container">
      <p><a href="..">UpshiftAI</a> — ancient dependency lineage. <a href="../pricing.html">Pricing</a> · <a href="https://github.com/repairman29/upshift" target="_blank" rel="noopener">GitHub</a></p>
    </div>
  </footer>
</body>
</html>
