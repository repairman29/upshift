<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>When it breaks, who fixes it, and why human-in-the-loop still matters | Upshift Blog</title>
  <meta name="description" content="Three questions experienced engineers ask about AI-powered dependency upgrades—when it breaks, CI/CD guardrails, and why human-in-the-loop still matters." />
  <meta property="og:title" content="When it breaks, who fixes it, and why human-in-the-loop still matters" />
  <meta property="og:description" content="Three questions experienced engineers ask about AI-powered dependency upgrades—and how we answer them." />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary_large_image" />
  <link rel="icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/favicon.svg" type="image/svg+xml" />
  <link rel="stylesheet" href="../styles.css" />
  <link rel="stylesheet" href="../blog.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet" />
  <script defer data-domain="upshiftai.dev" src="https://plausible.io/js/script.js"></script>
  <script defer src="/nav.js"></script>
</head>
<body>
  <header class="header">
    <div class="wrap">
      <a href="/" class="logo">upshift</a>
      <button type="button" class="nav-toggle" aria-label="Toggle menu" aria-expanded="false">☰</button>
      <nav class="nav-main">
        <a href="/#demo">Demo</a>
        <a href="/radar/">Radar</a>
        <a href="/#compare">vs Dependabot</a>
        <a href="/#pricing">Pricing</a>
        <a href="/docs/">Docs</a>
        <a href="/blog/index.html">Blog</a>
        <a href="https://api.upshiftai.dev" target="_blank" rel="noopener">Sign in</a>
        <a href="https://github.com/repairman29/upshift" class="nav-gh" target="_blank" rel="noopener">GitHub</a>
      </nav>
    </div>
  </header>

  <article class="blog-content">
    <a href="/blog/index.html" class="blog-back">← Blog</a>
    <p class="blog-meta">February 1, 2026 · 5 min read</p>
    <h1>When it breaks, who fixes it, and why human-in-the-loop still matters</h1>
    <p class="subtitle">Three questions experienced engineers ask about AI-powered dependency upgrades—and how we answer them.</p>

    <p>Dependency upgrades are boring until they break something. Then everyone wants to know: <em>when</em> did it break, <em>who</em> is supposed to catch it, and whether we're really letting an AI change code without a human in the loop.</p>
    <p>We get that. Here's how we think about it.</p>

    <h2>"When does it break?"</h2>
    <p><strong>At upgrade time.</strong> Not "sometime after a code push" or "when the moon is full." When you—or your CI—run <code>upshift upgrade &lt;pkg&gt;</code>, we change the manifest and lockfile, run your tests, and roll back if tests fail. The break is surfaced <em>at that moment</em> and reverted.</p>
    <p>So:</p>
    <ul>
      <li><strong>You run <code>upshift upgrade</code></strong> → We update <code>package.json</code> and the lockfile, then run <code>npm test</code>. If tests fail, we roll back. The "break" is immediate and undone.</li>
      <li><strong>CI runs Upshift</strong> → Same contract. Upgrade → run tests → fail the job (and optionally roll back) if tests fail. CI doesn't self-heal; it <em>surfaces</em> the problem. We use that same guardrail.</li>
      <li><strong>You run <code>upshift fix</code></strong> → That's for <em>code</em> changes (LLM-generated fixes for breaking API changes). You run it when you know an upgrade will break code, or after it already did. It's an explicit step, not something that fires automatically on push.</li>
    </ul>
    <p><strong>TL;DR:</strong> "Breaks when?" → When an upgrade is applied and tests run. Tests are the gate.</p>

    <h2>CI/CD and smoke tests: we're not replacing them</h2>
    <p>Today, CI/CD with smoke or integration tests <em>surfaces</em> problems. It doesn't self-heal. We're aligned with that:</p>
    <ul>
      <li>We <strong>run your tests</strong> after every upgrade (if you have a test script). If they fail, we roll back and exit with failure.</li>
      <li>We don't replace CI; we <strong>use the same guardrail</strong>: "tests pass = safe to keep the change."</li>
      <li>The GitHub Action runs a <strong>scan</strong> on PRs (outdated deps, risk). You can also run <code>upshift upgrade</code> in CI; the job fails if the upgrade breaks tests.</li>
    </ul>
    <p>Existing CI and test suites stay the source of truth. Upshift adds upgrade + optional code fixes on top of that contract.</p>

    <h2>Self-healing LLM code: why human-in-the-loop still matters</h2>
    <p><strong>LLM-generated code changes should be reviewed.</strong> "Self-healing" by applying AI-generated patches with no oversight is risky. We're not pretending otherwise.</p>
    <p>What we do today:</p>
    <ul>
      <li><strong><code>upshift fix --dry-run</code></strong> — Preview every suggested change. Review the diff, then apply manually or run <code>upshift fix</code> without <code>--dry-run</code> when you're satisfied.</li>
      <li><strong>Approval for upgrades</strong> — Major (and optionally other) upgrades can require a prompt or webhook approval before we touch the manifest or lockfile. See <a href="/blog/how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a> and the <a href="/docs/configuration.html#approval-hitl">approval (HITL) docs</a>.</li>
      <li><strong>No silent auto-apply of code fixes</strong> — Fixes are either shown for review (dry-run) or applied only after an explicit confirm (or <code>-y</code> in automation, where <em>you've</em> chosen to trust the pipeline).</li>
    </ul>
    <p>Recommendation: treat <strong>dependency upgrades</strong> as guardrailed by tests and optional approval. Treat <strong>LLM-generated code fixes</strong> as human-in-the-loop: review (dry-run, PR, or approval workflow) before merging. For how we implement approval (prompt vs webhook vs none) and quick setup, see <a href="/blog/how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a>; for webhook payloads and event hooks, see <a href="/docs/configuration.html#approval-hitl">approval (HITL) in the docs</a>.</p>

    <hr />

    <p>So: it breaks at upgrade time, tests are the guardrail, and we don't self-heal code without giving you a way to stay in the loop. If that matches how you want to work, give Upshift a try.</p>

    <div class="blog-cta">
      <h3>Try Upshift Today</h3>
      <p>Stop reading changelogs. Let AI tell you what breaks.</p>
      <a href="/start" class="btn btn-primary">Get Started</a>
    </div>

    <div class="blog-more">
      <strong>More from the blog</strong>
      <a href="/blog/how-we-do-hitl.html">How we do human-in-the-loop (HITL)</a> — prompt vs webhook vs none, config, and quick setup.
      <p class="blog-signature">— The Upshift Team</p>
    </div>
  </article>

  <footer class="footer">
    <div class="wrap">
      <p>&copy; 2026 Upshift. Built for developers who ship.</p>
    </div>
  </footer>
</body>
</html>
